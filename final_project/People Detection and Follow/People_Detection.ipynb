{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# People Detection and Follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.46 feature points in frame ( in average of 24 frames )\n",
      "32.46 feature points in frame ( in average of 24 frames )\n",
      "34.42 feature points in frame ( in average of 24 frames )\n",
      "42.71 feature points in frame ( in average of 24 frames )\n",
      "33.17 feature points in frame ( in average of 24 frames )\n",
      "29.67 feature points in frame ( in average of 24 frames )\n",
      "84.92 feature points in frame ( in average of 24 frames )\n",
      "99.08 feature points in frame ( in average of 24 frames )\n",
      "105.58 feature points in frame ( in average of 24 frames )\n",
      "114.17 feature points in frame ( in average of 24 frames )\n",
      "107.5 feature points in frame ( in average of 24 frames )\n",
      "124.17 feature points in frame ( in average of 24 frames )\n",
      "102.54 feature points in frame ( in average of 24 frames )\n",
      "128.62 feature points in frame ( in average of 24 frames )\n",
      "157.25 feature points in frame ( in average of 24 frames )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# from imutils.object_detection import non_max_suppression\n",
    "\n",
    "# Dependencies :\n",
    "# pip install numpy\n",
    "# pip install opencv-python\n",
    "# pip install imutils\n",
    "\n",
    "# flag to indicate if there was click on the screen\n",
    "r_clicked = False\n",
    "l_clicked = False\n",
    "window_name = 'People detection ( left click : redetection , right click : take screenshot )'\n",
    "\n",
    "\n",
    "ped_cascade = cv2.CascadeClassifier('pedestrian.xml')\n",
    "\n",
    "\n",
    "# Image Editing Help Methods\n",
    "\n",
    "def detect_people(img):\n",
    "    orig = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect people in the image\n",
    "    rects = ped_cascade.detectMultiScale(orig, 1.1, 2)\n",
    "    rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "\n",
    "    return rects\n",
    "\n",
    "\n",
    "def point_inside_rect(p, rect):\n",
    "    return rect[0] <= p[0] <= rect[2] and rect[1] <= p[1] <= rect[3]\n",
    "\n",
    "\n",
    "def get_point_rect_index(p, rects):\n",
    "    for i in range(len(rects)):\n",
    "        if point_inside_rect(p, rects[i]):\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "# events\n",
    "\n",
    "def screen_click(event, x, y, flags, param):\n",
    "    global l_clicked\n",
    "    global r_clicked\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        l_clicked = True\n",
    "    if event == cv2.EVENT_RBUTTONUP:\n",
    "        r_clicked = True\n",
    "\n",
    "\n",
    "# set event to windows click\n",
    "cv2.namedWindow(window_name)\n",
    "cv2.setMouseCallback(window_name, screen_click)\n",
    "\n",
    "\n",
    "def main():\n",
    "    global l_clicked\n",
    "    global r_clicked\n",
    "    write_output_video = True # set this to True if you want to record and save video\n",
    "\n",
    "    # Consts\n",
    "\n",
    "    video = 'v1.mp4'\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=9999,\n",
    "                          qualityLevel=0.1,\n",
    "                          minDistance=16,\n",
    "                          blockSize=11)\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(winSize=(30, 30),\n",
    "                     maxLevel=2,\n",
    "                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.01))\n",
    "\n",
    "    colors = np.random.randint(0, 255, (400, 3))\n",
    "    frames_limit = 1 * 24 # number of frames between the redetection\n",
    "    follow_disappear_rate = 0.95 # the rate of mask disappear\n",
    "    point_limit_ratio = 0.9 # the low threshold that indicate to redetect feature points ( like we did in class when there are not enough points )\n",
    "    frame_counter_text_color = (255, 255, 255)\n",
    "    frame_counter_text_pos = (6, 26)\n",
    "    frame_counter_text_size = 1.75\n",
    "    screenshot_pos = (6, 46)\n",
    "    screeshot_text_size = 1.45\n",
    "    screenshot_text_color = (0, 0, 255)\n",
    "    screenshot_text_string = 'screen shot has been saved'\n",
    "\n",
    "    \n",
    "    # start of video capture\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    out = None\n",
    "    \n",
    "    # video record parameters\n",
    "    if write_output_video:\n",
    "        video_attr = ('out', 'mp4v', 20.0, old_gray.shape[1], old_gray.shape[0], '.mp4')\n",
    "        fourcc = cv2.VideoWriter_fourcc(*video_attr[1])\n",
    "        video_name = '{0}_{1}_{2}_{3}_{4}_output{5}'.format(*video_attr)\n",
    "        out = cv2.VideoWriter(video_name, fourcc, video_attr[2], (video_attr[3], video_attr[4]))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, **feature_params)\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    # detect the rectangles of the people in the current frame\n",
    "    all_people = detect_people(old_frame)\n",
    "    point_limit = len(p0) * point_limit_ratio\n",
    "    frame_counter = 0\n",
    "    fp_counter = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # recalc point if there are too few\n",
    "        if l_clicked:\n",
    "            print('looking for people in frame', frame_counter)\n",
    "        if frame_counter % frames_limit == 0 or len(all_people) < 2 or l_clicked:\n",
    "            all_people = detect_people(frame)\n",
    "            l_clicked = False\n",
    "        if len(p0) < point_limit or l_clicked:\n",
    "            p0 = np.concatenate((p0, cv2.goodFeaturesToTrack(frame_gray, 100, 0.01, 10, None, None, 9)))\n",
    "            point_limit = len(p0) * point_limit_ratio\n",
    "            l_clicked = False\n",
    "\n",
    "            \n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params, )\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "\n",
    "        # draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "\n",
    "            rect_id = get_point_rect_index(good_new[i], all_people)\n",
    "            if rect_id != -1:\n",
    "                # draw each point with the color of the person that it belongs to ( by the rect_id )\n",
    "                fp_counter += 1\n",
    "                mask = cv2.line(mask, (a, b), (c, d), colors[rect_id].tolist(), 2)\n",
    "                frame = cv2.circle(frame, (a, b), 1, colors[rect_id].tolist(), -1)\n",
    "        # write the number of the frame\n",
    "        frame = cv2.putText(frame, str(frame_counter), frame_counter_text_pos, cv2.FONT_HERSHEY_PLAIN,\n",
    "                            frame_counter_text_size,\n",
    "                            frame_counter_text_color)\n",
    "\n",
    "        # console stats\n",
    "        if frame_counter % frames_limit == 0:\n",
    "            print(np.round(fp_counter / frames_limit, 2),\n",
    "                  'feature points in frame ( in average of', frames_limit, 'frames )')\n",
    "            fp_counter = 0\n",
    "\n",
    "        # people trace followup\n",
    "        mask = (mask * follow_disappear_rate).astype(np.uint8)\n",
    "\n",
    "        # people counter\n",
    "        cv2.putText(frame, 'people : {0}'.format(len(all_people)), (6, frame.shape[0] - 20),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 1.75, (0, 0, 0))\n",
    "        img = cv2.add(frame, mask)\n",
    "        # for rect in all_people:\n",
    "\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        # for (a, b, c, d) in all_people:\n",
    "        # img = cv2.rectangle(img, (a, b), (c, d), (0, 255, 210), 4)\n",
    "\n",
    "        # screen show is taken on right mouse click\n",
    "        if r_clicked:\n",
    "            print('screenshot of frame', frame_counter, 'has been saved')\n",
    "            cv2.imwrite('screenshot_{0}.jpg'.format(frame_counter), img)\n",
    "            r_clicked = False\n",
    "            cv2.putText(img, screenshot_text_string, screenshot_pos, cv2.FONT_HERSHEY_PLAIN,\n",
    "                        screeshot_text_size,\n",
    "                        screenshot_text_color, 2)\n",
    "\n",
    "        cv2.imshow(window_name, img)\n",
    "        \n",
    "        # add frame to output video stream\n",
    "        if write_output_video:\n",
    "            out.write(img)\n",
    "            \n",
    "        # exit if esc was pressed\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "        if k == 27:\n",
    "            break\n",
    "        frame_counter += 1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    if write_output_video:\n",
    "        out.release()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
